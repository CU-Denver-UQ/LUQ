{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Steven Mattis and Troy Butler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dynamical_systems as ds\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from luq import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is for harmonic motion\n",
    "$$y''(t) + 2cy'(t) + \\omega_0^2 x = f(t)$$\n",
    "with damping constant\n",
    "$$c \\in [0.1,1]$$\n",
    "and natural frequency\n",
    "$$\\omega_0\\in[0.5,2]$$\n",
    "and forcing term initially taken to be zero.\n",
    "\n",
    "Note that with the ranges of $c$ and $\\omega_0$ above, it is possible for the system to either be under-, over-, or critically damped (and since $c\\geq 0.1$ it is never undamped, which is almost always physical nonsense). \n",
    "\n",
    "The roots to the characteristic equation are given by\n",
    "$$ r_1 = -c\\pm \\sqrt{c^2-\\omega_0^2}$$.\n",
    "\n",
    "When the system is under-damped, the solution is given by\n",
    "$$ y(t) = e^{-ct}[C_1\\cos(\\omega t) + C_2\\sin(\\omega t)], \\ \\omega=\\sqrt{\\omega_0^2-c^2}. $$\n",
    "\n",
    "\n",
    "When the system is over-damped, the solution is given by \n",
    "$$ y(t) = C_1 e^{r_1t}+C_2 e^{r_2t}. $$\n",
    "\n",
    "And, finally, when the system is critically damped, the solution is given by\n",
    "$$ y(t) = C_1e^{-ct} + C_2 te^{-ct}. $$\n",
    "\n",
    "However, we never expect the system to be critically damped in practice since this is \"too fine-tuned\" of a scenario. \n",
    "\n",
    "The constants $C_1$ and $C_2$ are determined by the initial conditions, which we assume to be given by\n",
    "$$ y(0)=a, y'(0) = b $$\n",
    "where \n",
    "$$ a\\in[1,2] $$ \n",
    "and \n",
    "$$ b\\in[-1,0] $$. \n",
    "\n",
    "In the under-damped case, \n",
    "$$ C_1 = a, \\ \\text{and } \\ C_2 = \\frac{b+ca}{\\omega}. $$\n",
    "\n",
    "In the over-damped case, \n",
    "$$ C_1 = \\frac{b-ar_2}{r_1-r_2}, \\ \\text{and } \\ C_2 = \\frac{b-r_1a}{r_2-r_1} $$\n",
    "\n",
    "A ***true*** distribution of $c, \\omega_0, a$, and $b$ are defined by (non-uniform)\n",
    "Beta distributions and used to generate a set of time series data.\n",
    "\n",
    "An ***initial*** uniform distribution is assumed and updated by the true time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample the parameter samples to form a \"prediction\" or \"test\" set\n",
    "num_samples = int(1E3)\n",
    "\n",
    "params = np.random.uniform(size=(num_samples, 2))\n",
    "ics = np.random.uniform(size=(num_samples, 2))\n",
    "\n",
    "param_range = np.array([[0.1, 1.0],  # c\n",
    "                        [0.5, 2.0]])  # omega_0\n",
    "ic_range = np.array([[1.0, 2.0],  #a\n",
    "                     [-1.0, 0.0]])  #b\n",
    "params = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params\n",
    "ics = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics\n",
    "param_labels = [r'$c$', r'$\\omega_0$']\n",
    "ic_labels = [r'$a$', r'$b$']\n",
    "\n",
    "# Construct the predicted time series data\n",
    "\n",
    "num_time_preds = int(50)  # number of predictions (uniformly space) between [time_start,time_end]\n",
    "time_start = 0.5\n",
    "time_end = 3.5\n",
    "times = np.linspace(time_start, time_end, num_time_preds)\n",
    "\n",
    "phys = ds.HarmonicOscillator()\n",
    "predicted_time_series = phys.solve(ics=ics, params=params, t_eval=times)\n",
    "\n",
    "\n",
    "# Simulate an observed Beta distribution of time series data\n",
    "\n",
    "num_obs = int(1E3)\n",
    "\n",
    "true_a = 2\n",
    "true_b = 2\n",
    "\n",
    "params_obs = np.random.beta(size=(num_obs, 2), a=true_a, b=true_b)\n",
    "ics_obs = np.random.beta(size=(num_obs, 2), a=true_a, b=true_b)\n",
    "params_obs = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params_obs\n",
    "ics_obs = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics_obs\n",
    "\n",
    "observed_time_series = phys.solve(ics=ics_obs, params=params_obs, t_eval=times)\n",
    "\n",
    "# Add noise if desired\n",
    "with_noise = False\n",
    "noise_stdev = 0.05\n",
    "\n",
    "if with_noise:\n",
    "    observed_time_series += noise_stdev * np.random.randn(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LUQ to learn dynamics and QoIs\n",
    "learn = LUQ(predicted_time_series, observed_time_series, times)\n",
    "\n",
    "# time array indices over which to use\n",
    "time_start_idx = 0\n",
    "time_end_idx = 49\n",
    "\n",
    "# Clean data with piecewise linear splines\n",
    "learn.clean_data(time_start_idx=time_start_idx, time_end_idx=time_end_idx,\n",
    "                     num_clean_obs=50, tol=1.0e-2, min_knots=5, max_knots=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn and classify dynamics\n",
    "learn.dynamics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters of predicted time series\n",
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2.5), gridspec_kw={'width_ratios': [3, 1]}) \n",
    "    ps = []\n",
    "    for i in range(num_samples):\n",
    "        if learn.predict_labels[i] == j:\n",
    "            ps.append(params[i,0]/params[i,1])\n",
    "            ax1.plot(learn.clean_times, learn.clean_predictions[i, :])\n",
    "    ax1.set(title='Cluster ' + str(j))\n",
    "    xs = np.linspace(0.05, 2.0, 100)\n",
    "    ax2.plot(xs, GKDE(ps)(xs))\n",
    "    ax2.set(xlabel=r'$c/\\omega_0$', title='Param. Distrib.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot oberved and predicted clusters\n",
    "for j in range(learn.num_clusters):\n",
    "    plt.figure()\n",
    "    cluster_num = j\n",
    "    for i in range(num_samples):\n",
    "        if learn.predict_labels[i] == cluster_num:\n",
    "            plt.plot(learn.clean_times, learn.clean_predictions[i,:],'b*')\n",
    "    for i in range(num_obs):\n",
    "        if learn.obs_labels[i] == cluster_num:\n",
    "            plt.plot(learn.clean_times, learn.clean_obs[i,:],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best KPCA transformation for given number of QoI and transform time series data.\n",
    "predict_map, obs_map = learn.learn_qois_and_transform(num_qoi=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate kernel density estimates on new QoI\n",
    "learn.generate_kdes()\n",
    "# Calculate rejection rates for each cluster and print averages.\n",
    "r_vals = learn.compute_r()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_marginals = []\n",
    "ic_marginals = []\n",
    "true_param_marginals = []\n",
    "true_ic_marginals = []\n",
    "lam_ptr = []\n",
    "cluster_weights = []\n",
    "for i in range(learn.num_clusters):\n",
    "    lam_ptr.append(np.where(learn.predict_labels == i)[0])\n",
    "    cluster_weights.append(len(np.where(learn.obs_labels == i)[0]) / num_obs)\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    true_param_marginals.append(GKDE(params_obs[:,i]))\n",
    "    param_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        param_marginals[i].append(GKDE(params[lam_ptr[j], i], weights=learn.r[j]))\n",
    "        \n",
    "for i in range(ics.shape[1]):\n",
    "    true_ic_marginals.append(GKDE(ics_obs[:,i]))\n",
    "    ic_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        ic_marginals[i].append(GKDE(ics[lam_ptr[j], i], weights=learn.r[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unif_dist(x, p_range):\n",
    "    y = np.zeros(x.shape)\n",
    "    val = 1.0/(p_range[1] - p_range[0])\n",
    "    for i, xi in enumerate(x):\n",
    "        if xi < p_range[0] or xi >  p_range[1]:\n",
    "            y[i] = 0\n",
    "        else:\n",
    "            y[i] = val\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(params.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(params[:, i]), min(params_obs[:, i]))\n",
    "    x_max = max(max(params[:, i]), max(params_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, param_range[i, :]),\n",
    "         label = 'Initial guess')\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Estimated pullback')\n",
    "    plt.plot(x, true_param_marginals[i](x), label = 'Actual density')\n",
    "    plt.title('Comparing pullback to actual density of parameter ' + param_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ics.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(ics[:, i]), min(ics_obs[:, i]))\n",
    "    x_max = max(max(ics[:, i]), max(ics_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, ic_range[i, :]),\n",
    "         label = 'Initial guess')\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += ic_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Estimated pullback')\n",
    "    plt.plot(x, true_ic_marginals[i](x), label = 'Actual density')\n",
    "    plt.title('Comparing pullback to actual density of initial condition ' + ic_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
