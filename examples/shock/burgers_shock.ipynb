{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019-2020 Steven Mattis and Troy Butler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from luq.luq import *\n",
    "import ipywidgets as wd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams.update({'axes.linewidth': 2})\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the 1D Burger's equation, a nonlinear PDE used to model fluid dynamics:\n",
    "$$q_t + \\frac{1}{2} (q^2)_x = 0.$$\n",
    "The domain is the interval $[0, 10]$.\n",
    "We have an initial condition of the form\n",
    "\\begin{equation*}\n",
    "q(x,0) = \\begin{cases} \n",
    "      f_l & 0 \\leq x\\leq 3.25 -a  \\\\\n",
    "       \\frac{1}{2} ((f_l + f_r) - (f_l - f_r) \\frac{(x-3.25)}{a}) & 3.25 -a < x \\leq 3.25 + a \\\\\n",
    "      f_r & 3.25 + a < x \\leq 10,\n",
    "   \\end{cases}\n",
    "\\end{equation*}\n",
    "where $a \\in [0, 3]$ is an uncertain parameter and $f_l$ and $f_r$ are positive constants with $f_l > f_r$. \n",
    "Take $f_l = 1.5$ and $f_r = 1$.\n",
    "We assume non-reflecting boundary conditions, allowing waves to pass out of the boundaries without reflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the initial condition given a, fl, and fr.\n",
    "As = [0.75, 1.875, 3.0]\n",
    "ss = ['-k', '--b', '-.r']\n",
    "\n",
    "fl = 1.5; fr = 1;\n",
    "x = np.linspace(0, 10, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "q0 = np.zeros(x.shape)\n",
    "for j,a in enumerate(As):\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i] <= (3.25 - a):\n",
    "            q0[i] = fl\n",
    "        elif x[i] > (3.25 + a):\n",
    "            q0[i] = fr\n",
    "        else:\n",
    "             q0[i] = 0.5 * ((fl + fr) - (fl - fr) * (x[i] - 3.25) / a)\n",
    "    ax.plot(x, q0, ss[j], linewidth=2, label=\"a=\"+str(a))\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"q(x,0)\")\n",
    "ax.legend()\n",
    "ax.set_xticks((0, 6.5, 9.5))\n",
    "ax.set_title('Initial Conditions')\n",
    "ax.axvline(x=6.5, color='c')\n",
    "ax.axvline(x=9.5, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This system often can develop discontinuous solutions (shock waves), which complicates calculating a numerical solution. \n",
    "We use Clawpack (https://www.clawpack.org/) to calculate weak solutions to the system using a Godunov-type finite volume method with an appropriate limiter and Riemann solver. \n",
    "We use a uniform mesh with 500 elements.\n",
    "\n",
    "The system described above forms a shock at $t = \\frac{2a}{f_l - f_r}$.\n",
    "The shock speed is $\\frac{1}{2}(f_l + f_r)$.\n",
    "\n",
    "We calculte the time series solution at $x=7$, i.e. $q(7,t)$ at 500 evenly spaced time steps between 0 and 10.\n",
    "\n",
    "Two ***true*** distributions of $a$ are defined by (non-uniform)\n",
    "Beta distributions and used to generate a set of time series data.\n",
    "\n",
    "An ***initial*** uniform distribution is assumed and updated by the true time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed time-series data.\n",
    "times = np.loadtxt('burgers_files/unif_times.txt')\n",
    "predicted_time_series = np.loadtxt('burgers_files/unif_series.txt')\n",
    "params = np.loadtxt('burgers_files/unif_params.txt')\n",
    "num_samples = predicted_time_series.shape[0]\n",
    "\n",
    "# a=5, b=2\n",
    "observed_time_series = np.loadtxt('burgers_files/beta_series_2_2.txt')\n",
    "params_obs = np.loadtxt('burgers_files/beta_params_2_2.txt')\n",
    "num_obs = observed_time_series.shape[0]\n",
    "\n",
    "if len(params.shape) == 1:\n",
    "    params = params.reshape((num_samples, 1))\n",
    "    params_obs = params_obs.reshape((num_obs, 1))\n",
    "    \n",
    "# Add noise if desired\n",
    "with_noise = True\n",
    "noise_stdev = 0.025\n",
    "\n",
    "if with_noise:\n",
    "    predicted_time_series += noise_stdev * np.random.randn(num_samples, times.shape[0])\n",
    "    observed_time_series += noise_stdev * np.random.randn(num_obs, times.shape[0])\n",
    "param_range = np.array([[0.75, 3.0]])\n",
    "param_labels = [r'$a$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use LUQ to learn dynamics and QoIs\n",
    "learn = LUQ(predicted_data=predicted_time_series, \n",
    "            observed_data=observed_time_series)\n",
    "\n",
    "# time array indices over which to use\n",
    "time_start_idx = 0 #0\n",
    "time_end_idx = 499 #499\n",
    "\n",
    "num_filtered_obs = 500\n",
    "\n",
    "filtered_times = np.linspace(times[time_start_idx],\n",
    "                             times[time_end_idx],\n",
    "                             num_filtered_obs)\n",
    "\n",
    "# Filter data with piecewise linear splines\n",
    "learn.filter_data(filter_method='splines',\n",
    "                  predicted_data_coordinates=times,\n",
    "                  observed_data_coordinates=times,\n",
    "                  filtered_data_coordinates=filtered_times,\n",
    "                  tol=0.5*noise_stdev, \n",
    "                  min_knots=3, \n",
    "                  max_knots=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn and classify dynamics.\n",
    "learn.dynamics(cluster_method='kmeans', kwargs={'n_clusters': 2, 'n_init': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "# chosen_obs = [109, 8]\n",
    "\n",
    "chosen_obs = [1, 3, 6]  #7]\n",
    "colors = ['r', 'g', 'b']\n",
    "\n",
    "for i, c in zip(chosen_obs,colors):\n",
    "    plt.plot(learn.observed_data_coordinates[time_start_idx:time_end_idx+1], learn.observed_data[i,time_start_idx:time_end_idx+1],color=c, linestyle='none', marker='.', markersize=10, alpha=0.25)\n",
    "    \n",
    "for i in chosen_obs:\n",
    "    num_i_knots = int(0.5*(2+len(learn.obs_knots[i])))\n",
    "    knots = np.copy(learn.obs_knots[i][num_i_knots:])\n",
    "    knots = np.insert(knots, 0, learn.filtered_data_coordinates[0])\n",
    "    knots = np.append(knots, learn.filtered_data_coordinates[-1])\n",
    "    plt.plot(knots, learn.obs_knots[i][:num_i_knots], 'k', linestyle='dashed', markersize=15, marker='o', linewidth=2)\n",
    "    \n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y(t)$')\n",
    "plt.title('Approximating Dynamics') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for i, c in zip(chosen_obs,colors):\n",
    "    plt.plot(learn.observed_data_coordinates[time_start_idx:time_end_idx+1], learn.observed_data[i,time_start_idx:time_end_idx+1],color=c, linestyle='none', marker='.', markersize=10, alpha=0.25)\n",
    "    \n",
    "for i in chosen_obs:\n",
    "    plt.plot(learn.filtered_data_coordinates, learn.filtered_obs[i,:],'k', linestyle='none', marker='s', \n",
    "            markersize=12)\n",
    "    \n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y(t)$')\n",
    "plt.title('Generating Clean Data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot clusters of predicted time series\n",
    "num_filtered_obs = learn.filtered_data_coordinates.shape[0]\n",
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]}) \n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,num_samples).reshape(num_samples, num_filtered_obs), \n",
    "                learn.filtered_predictions, 50, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn.filtered_predictions[idx,:], 50, c='b', marker='o', alpha=0.2)\n",
    "    idx2 = np.where(learn.obs_labels == j)[0]    \n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,len(idx2)).reshape(len(idx2),num_filtered_obs), \n",
    "                learn.filtered_obs[idx2, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    ax1.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "    ax1.set_xlabel('$t$')\n",
    "    ax1.set_ylabel('$x(t)$')\n",
    "    \n",
    "    xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    ax2.plot(xs, GKDE(params[idx].flat[:])(xs))\n",
    "    ax2.axvline(x=.65, ymin=0.0, ymax=1.0, color='r')\n",
    "    ax2.set(xlabel=param_labels[0], title='Param. Distrib.')\n",
    "    \n",
    "#     ax2.scatter(params[:,0], params[:,1], 30, c='gray', marker='.', alpha=0.2)\n",
    "#     ax2.scatter(params[idx,0], params[idx,1], 50, c='blue', marker='o')\n",
    "#     ax2.set(title='Cluster ' + str(j+1) + ' in parameters')\n",
    "#     ax2.set_ylabel(param_labels[1])\n",
    "#     ax2.set_xlabel(param_labels[0])\n",
    "#     xs = np.linspace(param_range[0,0], param_range[0,1], 100)\n",
    "#     ys1 = np.sqrt(0.5*(1.0 - np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ys2 = np.sqrt(0.5*(1.0 + np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ax2.plot(xs, ys1, 'r-', linewidth=3)\n",
    "#     ax2.plot(xs, ys2, 'r-', linewidth=3)\n",
    "    fig.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot clusters of predicted time series\n",
    "# for j in range(learn.num_clusters):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2.5), gridspec_kw={'width_ratios': [3, 1]}) #(figsize=(10,5))\n",
    "#     ps = []\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == j:\n",
    "#             ps.append(params[i,0])\n",
    "#             ax1.plot(learn.filtered_data_coordinates, learn.filtered_predictions[i, :])\n",
    "#             #ax1.plot(times[time_start_idx : time_end_idx + 1], predicted_time_series[i, time_start_idx : time_end_idx + 1])\n",
    "#     ax1.set(title='Cluster ' + str(j))\n",
    "#     xs = np.linspace(param_range[0, 0], param_range[0,1], 100)\n",
    "#     ax2.plot(xs, GKDE(ps)(xs))\n",
    "#     ax2.set(xlabel=param_labels[0], title='Param. Distrib.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot observed and predicted clusters\n",
    "# for j in range(learn.num_clusters):\n",
    "#     plt.figure()\n",
    "#     cluster_num = j\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == cluster_num:\n",
    "#             plt.plot(learn.filtered_data_coordinates, learn.filtered_predictions[i,:],'b*')\n",
    "#     for i in range(num_obs):\n",
    "#         if learn.obs_labels[i] == cluster_num:\n",
    "#             plt.plot(learn.filtered_data_coordinates, learn.filtered_obs[i,:],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best KPCA transformation for given number of QoI and transform time series data.\n",
    "predict_map, obs_map = learn.learn_qois_and_transform(num_qoi=1)\n",
    "#                                                     proposals=({'kernel': 'linear'}, {'kernel': 'rbf'}))\n",
    "#                             {'kernel': 'sigmoid'}, {'kernel': 'cosine'})) #variance_rate=0.95) #num_qoi=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "def plot_gap(all_eig_vals, n, cluster):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    #Plotting until maximum number of knots\n",
    "    eig_vals = all_eig_vals[cluster].eigenvalues_[0:10]\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals/np.sum(eig_vals)*100, marker='.', markersize=20, linestyle='')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'k--')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n+1]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'r--')\n",
    "    plt.text(n+1, eig_vals[n]/np.sum(eig_vals)*150, \n",
    "             r'%2.3f' %(np.sum(eig_vals[0:n+1])/np.sum(eig_vals)*100) + '% of variation explained by first ' + '%1d' %(n+1) + ' PCs.', \n",
    "                                                               {'color': 'k', 'fontsize': 20})\n",
    "    plt.text(n+2, eig_vals[n+1]/np.sum(eig_vals)*150, \n",
    "             r'Order of magnitude of gap is %4.2f.' %(np.log10(eig_vals[n])-np.log10(eig_vals[n+1])), \n",
    "                                                               {'color': 'r', 'fontsize': 20})\n",
    "    s = 'Determining QoI for cluster #%1d' %(cluster+1)\n",
    "    plt.title(s)\n",
    "    plt.xlabel('Principal Component #')\n",
    "    plt.ylabel('% of Variation')\n",
    "    plt.xlim([0.1, np.size(eig_vals)+1])\n",
    "    plt.ylim([1e-5,500])\n",
    "\n",
    "\n",
    "wd.interact(plot_gap, all_eig_vals=wd.fixed(learn.kpcas),\n",
    "            n = wd.IntSlider(value=0, min=0, max=5),\n",
    "            cluster = wd.IntSlider(value=0, min=0, max=learn.num_clusters-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate kernel density estimates on new QoI and calculate new weights\n",
    "pi_predict_kdes = []\n",
    "pi_obs_kdes = []\n",
    "r_vals = []\n",
    "r_means = []\n",
    "for i in range(learn.num_clusters):\n",
    "    pi_predict_kdes.append(GKDE(learn.predict_maps[i].T))\n",
    "    pi_obs_kdes.append(GKDE(learn.obs_maps[i].T))\n",
    "    r_vals.append(\n",
    "        np.divide(\n",
    "            pi_obs_kdes[i](\n",
    "                learn.predict_maps[i].T), \n",
    "            pi_predict_kdes[i](\n",
    "                learn.predict_maps[i].T)))\n",
    "    r_means.append(np.mean(r_vals[i]))\n",
    "print(f'Diagnostics: {r_means}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute marginal probablities for each parameter and initial condition.\n",
    "param_marginals = []\n",
    "true_param_marginals = []\n",
    "lam_ptr = []\n",
    "cluster_weights = []\n",
    "for i in range(learn.num_clusters):\n",
    "    lam_ptr.append(np.where(learn.predict_labels == i)[0])\n",
    "    cluster_weights.append(len(np.where(learn.obs_labels == i)[0]) / num_obs)\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    true_param_marginals.append(GKDE(params_obs[:,i]))\n",
    "    param_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        param_marginals[i].append(GKDE(params[lam_ptr[j], i], weights=r_vals[j]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform distribution\n",
    "def unif_dist(x, p_range):\n",
    "    y = np.zeros(x.shape)\n",
    "    val = 1.0/(p_range[1] - p_range[0])\n",
    "    for i, xi in enumerate(x):\n",
    "        if xi < p_range[0] or xi >  p_range[1]:\n",
    "            y[i] = 0\n",
    "        else:\n",
    "            y[i] = val\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted marginal densities for parameters\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(params[:, i]), min(params_obs[:, i]))\n",
    "    x_max = max(max(params[:, i]), max(params_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, param_range[i, :]),\n",
    "         label = 'Initial', linewidth=4)\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Updated', linewidth=4, linestyle='dashed')\n",
    "    plt.plot(x, true_param_marginals[i](x), label = 'Data-generating', \n",
    "             linewidth=4, linestyle='dotted')\n",
    "    plt.title('Comparing pullback to actual density of parameter ' + param_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TV metric between densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quadrature as quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_init_error(x):\n",
    "    return np.abs(unif_dist(x,param_range[param_num, :])-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(param_init_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_update_KDE_error(x):\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[param_num][j](x) * cluster_weights[j]\n",
    "    return np.abs(mar-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(param_update_KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_a = 2.0\n",
    "true_b = 2.0\n",
    "def KDE_error(x):\n",
    "    true_beta = beta(a=true_a, b=true_b,loc=param_range[i,0],scale=param_range[i,1]-param_range[i,0])\n",
    "    return np.abs(true_beta.pdf(x)-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed time-series data at x=9.5.\n",
    "# a=2, b=5\n",
    "predicted_time_series2 = np.loadtxt('burgers_files/unif_series2.txt')\n",
    "observed_time_series2 = np.loadtxt('burgers_files/beta_series2_2_2.txt')\n",
    "params_obs2 = np.loadtxt('burgers_files/beta_params_2_2.txt')\n",
    "num_obs2 = observed_time_series.shape[0]\n",
    "params_obs2 = params_obs2.reshape((num_obs2, 1))\n",
    "\n",
    "# Add noise if desired\n",
    "with_noise = True\n",
    "noise_stdev = 0.025\n",
    "\n",
    "if with_noise:\n",
    "    predicted_time_series2 += noise_stdev * np.random.randn(num_samples, times.shape[0])\n",
    "    observed_time_series2 += noise_stdev * np.random.randn(num_obs2, times.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use LUQ to learn dynamics and QoIs\n",
    "learn2 = LUQ(predicted_data=predicted_time_series2, \n",
    "             observed_data=observed_time_series2)\n",
    "\n",
    "# time array indices over which to use\n",
    "time_start_idx = 250 #0\n",
    "time_end_idx = 749 #499\n",
    "\n",
    "num_filtered_obs = 500\n",
    "\n",
    "filtered_times = np.linspace(times[time_start_idx],\n",
    "                             times[time_end_idx],\n",
    "                             num_filtered_obs)\n",
    "\n",
    "# Filter data with piecewise linear splines\n",
    "learn2.filter_data(filter_method='splines_tol',\n",
    "                  predicted_data_coordinates=times,\n",
    "                  observed_data_coordinates=times,\n",
    "                  filtered_data_coordinates=filtered_times,\n",
    "                  tol=0.5*noise_stdev, \n",
    "                  min_knots=3, \n",
    "                  max_knots=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn and classify dynamics.\n",
    "learn2.dynamics(cluster_method='kmeans', kwargs={'n_clusters': 2, 'n_init': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot clusters of predicted time series\n",
    "# for j in range(learn.num_clusters):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2.5), gridspec_kw={'width_ratios': [3, 1]}) #(figsize=(10,5))\n",
    "#     ps = []\n",
    "#     for i in range(num_samples):\n",
    "#         if learn2.predict_labels[i] == j:\n",
    "#             ps.append(params[i,0])\n",
    "#             ax1.plot(learn2.filtered_data_coordinates, learn2.filtered_predictions[i, :])\n",
    "#             #ax2.plot(times[time_start_idx : time_end_idx + 1], predicted_time_series[i, time_start_idx : time_end_idx + 1])\n",
    "#     ax1.set(title='Cluster ' + str(j))\n",
    "#     xs = np.linspace(param_range[0, 0], param_range[0,1], 100)\n",
    "#     ax2.plot(xs, GKDE(ps)(xs))\n",
    "#     ax2.set(xlabel=param_labels[0], title='Param. Distrib.')\n",
    "\n",
    "# # Plot clusters of predicted time series\n",
    "num_filtered_obs2 = learn2.filtered_data_coordinates.shape[0]\n",
    "for j in range(learn2.num_clusters):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]}) \n",
    "    ax1.scatter(np.tile(learn2.filtered_data_coordinates,num_samples).reshape(num_samples, num_filtered_obs2), \n",
    "                learn2.filtered_predictions, 50, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn2.predict_labels == j)[0]\n",
    "    ax1.scatter(np.tile(learn2.filtered_data_coordinates,len(idx)).reshape(len(idx),num_filtered_obs2), \n",
    "                learn2.filtered_predictions[idx,:], 50, c='b', marker='o', alpha=0.2)\n",
    "    idx2 = np.where(learn2.obs_labels == j)[0]    \n",
    "    ax1.scatter(np.tile(learn2.filtered_data_coordinates,len(idx2)).reshape(len(idx2),num_filtered_obs), \n",
    "                learn2.filtered_obs[idx2, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    ax1.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "    ax1.set_xlabel('$t$')\n",
    "    ax1.set_ylabel('$x(t)$')\n",
    "    \n",
    "    xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    ax2.plot(xs, GKDE(params[idx].flat[:])(xs))\n",
    "    ax2.axvline(x=1.25, ymin=0.0, ymax=1.0, color='r')\n",
    "\n",
    "    ax2.set(xlabel=param_labels[0], title='Param. Distrib.')\n",
    "    \n",
    "#     ax2.scatter(params[:,0], params[:,1], 30, c='gray', marker='.', alpha=0.2)\n",
    "#     ax2.scatter(params[idx,0], params[idx,1], 50, c='blue', marker='o')\n",
    "#     ax2.set(title='Cluster ' + str(j+1) + ' in parameters')\n",
    "#     ax2.set_ylabel(param_labels[1])\n",
    "#     ax2.set_xlabel(param_labels[0])\n",
    "#     xs = np.linspace(param_range[0,0], param_range[0,1], 100)\n",
    "#     ys1 = np.sqrt(0.5*(1.0 - np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ys2 = np.sqrt(0.5*(1.0 + np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ax2.plot(xs, ys1, 'r-', linewidth=3)\n",
    "#     ax2.plot(xs, ys2, 'r-', linewidth=3)\n",
    "    fig.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot observed and predicted clusters\n",
    "# for j in range(learn2.num_clusters):\n",
    "#     plt.figure()\n",
    "#     cluster_num = j\n",
    "#     for i in range(num_samples):\n",
    "#         if learn2.predict_labels[i] == cluster_num:\n",
    "#             plt.plot(learn2.filtered_data_coordinates, learn2.filtered_predictions[i,:],'b*')\n",
    "#     for i in range(num_obs2):\n",
    "#         if learn2.obs_labels[i] == cluster_num:\n",
    "#             plt.plot(learn2.filtered_data_coordinates, learn2.filtered_obs[i,:],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best KPCA transformation for given number of QoI and transform time series data.\n",
    "predict_map2, obs_map2 = learn2.learn_qois_and_transform(num_qoi=1) #variance_rate=0.95) #num_qoi=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "def plot_gap(all_eig_vals, n, cluster):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    #Plotting until maximum number of knots\n",
    "    eig_vals = all_eig_vals[cluster].eigenvalues_[0:10]\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals/np.sum(eig_vals)*100, marker='.', markersize=20, linestyle='')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'k--')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n+1]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'r--')\n",
    "    plt.text(n+1, eig_vals[n]/np.sum(eig_vals)*150, \n",
    "             r'%2.3f' %(np.sum(eig_vals[0:n+1])/np.sum(eig_vals)*100) + '% of variation explained by first ' + '%1d' %(n+1) + ' PCs.', \n",
    "                                                               {'color': 'k', 'fontsize': 20})\n",
    "    plt.text(n+2, eig_vals[n+1]/np.sum(eig_vals)*150, \n",
    "             r'Order of magnitude of gap is %4.2f.' %(np.log10(eig_vals[n])-np.log10(eig_vals[n+1])), \n",
    "                                                               {'color': 'r', 'fontsize': 20})\n",
    "    s = 'Determining QoI for cluster #%1d' %(cluster+1)\n",
    "    plt.title(s)\n",
    "    plt.xlabel('Principal Component #')\n",
    "    plt.ylabel('% of Variation')\n",
    "    plt.xlim([0.1, np.size(eig_vals)+1])\n",
    "    plt.ylim([1e-5,500])\n",
    "\n",
    "\n",
    "wd.interact(plot_gap, all_eig_vals=wd.fixed(learn2.kpcas),\n",
    "            n = wd.IntSlider(value=0, min=0, max=5),\n",
    "            cluster = wd.IntSlider(value=0, min=0, max=learn2.num_clusters-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate kernel density estimates on new QoI and calculate new weights\n",
    "pi_predict_kdes2 = []\n",
    "pi_obs_kdes2 = []\n",
    "r_vals2 = []\n",
    "r_means2 = []\n",
    "for i in range(learn2.num_clusters):\n",
    "    pi_predict_kdes2.append(GKDE(learn2.predict_maps[i].T))\n",
    "    pi_obs_kdes2.append(GKDE(learn2.obs_maps[i].T))\n",
    "    r_vals2.append(\n",
    "        np.divide(\n",
    "            pi_obs_kdes2[i](\n",
    "                learn2.predict_maps[i].T), \n",
    "            pi_predict_kdes2[i](\n",
    "                learn2.predict_maps[i].T)))\n",
    "    r_means2.append(np.mean(r_vals2[i]))\n",
    "print(f'Diagnostics: {r_means2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute marginal probablities for each parameter and initial condition.\n",
    "param2_marginals = []\n",
    "true_param_marginals = []\n",
    "lam_ptr2 = []\n",
    "cluster_weights2 = []\n",
    "for i in range(learn2.num_clusters):\n",
    "    lam_ptr2.append(np.where(learn2.predict_labels == i)[0])\n",
    "    cluster_weights2.append(len(np.where(learn2.obs_labels == i)[0]) / num_obs)\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    true_param_marginals.append(GKDE(params_obs2[:,i]))\n",
    "    param2_marginals.append([])\n",
    "    for j in range(learn2.num_clusters):\n",
    "        param2_marginals[i].append(GKDE(params[lam_ptr2[j], i], weights=r_vals2[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted marginal densities for parameters\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(params[:, i]), min(params_obs[:, i]))\n",
    "    x_max = max(max(params[:, i]), max(params_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, param_range[i, :]),\n",
    "         label = 'Initial', linewidth=4)\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn2.num_clusters):\n",
    "        mar += param2_marginals[i][j](x) * cluster_weights2[j]\n",
    "    plt.plot(x, mar, label = 'Updated', linewidth=4, linestyle='dashed')\n",
    "    plt.plot(x, true_param_marginals[i](x), label = 'Data-generating', \n",
    "             linewidth=4, linestyle='dotted')\n",
    "    plt.title('Comparing pullback to actual density of parameter ' + param_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(params.shape[1]):\n",
    "#     param_num=i\n",
    "#     TV_metric = quad(param_init_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "#     print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param2_update_KDE_error(x):\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn2.num_clusters):\n",
    "        mar += param2_marginals[param_num][j](x) * cluster_weights2[j]\n",
    "    return np.abs(mar-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(param2_update_KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(params.shape[1]):\n",
    "#     param_num=i\n",
    "#     TV_metric = quad(KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "#     print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filtered_obs = learn.filtered_data_coordinates.shape[0]\n",
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]}) \n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,num_samples).reshape(num_samples, num_filtered_obs), \n",
    "                learn.filtered_predictions, 50, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn.filtered_predictions[idx,:], 50, c='b', marker='o', alpha=0.2)\n",
    "    idx2 = np.where(learn.obs_labels == j)[0]    \n",
    "    ax1.scatter(np.tile(learn.filtered_data_coordinates,len(idx2)).reshape(len(idx2),num_filtered_obs), \n",
    "                learn.filtered_obs[idx2, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    ax1.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "    ax1.set_xlabel('$t$')\n",
    "    ax1.set_ylabel('$q(x_1, t)$')\n",
    "    ax1.set_xlim(0.0, 7.5)\n",
    "\n",
    "    ax2.scatter(np.tile(learn2.filtered_data_coordinates,num_samples).reshape(num_samples, num_filtered_obs), \n",
    "                learn2.filtered_predictions, 50, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn2.predict_labels == j)[0]\n",
    "    ax2.scatter(np.tile(learn2.filtered_data_coordinates,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn2.filtered_predictions[idx,:], 50, c='b', marker='o', alpha=0.2)\n",
    "    idx2 = np.where(learn2.obs_labels == j)[0]    \n",
    "    ax2.scatter(np.tile(learn2.filtered_data_coordinates,len(idx2)).reshape(len(idx2),num_filtered_obs), \n",
    "                learn2.filtered_obs[idx2, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    ax2.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "    ax2.set_xlabel('$t$')\n",
    "    ax2.set_ylabel('$q(x_2, t)$')\n",
    "    ax2.set_xlim(0.0, 7.5)\n",
    "    \n",
    "    #xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    #ax2.plot(xs, GKDE(params[idx].flat[:])(xs))\n",
    "    #ax2.axvline(x=.65, ymin=0.0, ymax=1.0, color='r')\n",
    "    #ax2.set(xlabel=param_labels[0], title='Param. Distrib.')\n",
    "    \n",
    "#     ax2.scatter(params[:,0], params[:,1], 30, c='gray', marker='.', alpha=0.2)\n",
    "#     ax2.scatter(params[idx,0], params[idx,1], 50, c='blue', marker='o')\n",
    "#     ax2.set(title='Cluster ' + str(j+1) + ' in parameters')\n",
    "#     ax2.set_ylabel(param_labels[1])\n",
    "#     ax2.set_xlabel(param_labels[0])\n",
    "#     xs = np.linspace(param_range[0,0], param_range[0,1], 100)\n",
    "#     ys1 = np.sqrt(0.5*(1.0 - np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ys2 = np.sqrt(0.5*(1.0 + np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ax2.plot(xs, ys1, 'r-', linewidth=3)\n",
    "#     ax2.plot(xs, ys2, 'r-', linewidth=3)\n",
    "    fig.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    ax1.plot(xs, GKDE(params[idx].flat[:])(xs), linewidth=2)\n",
    "    ax1.axvline(x=.65, ymin=0.0, ymax=1.0, color='r')\n",
    "    ax1.set(xlabel=param_labels[0], title='Cluster ' + str(j+1) + \", loc. 1\")\n",
    "    ax1.set_ylabel('Density')\n",
    "    \n",
    "    idx = np.where(learn2.predict_labels == j)[0]\n",
    "    xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    ax2.plot(xs, GKDE(params[idx].flat[:])(xs), linewidth=2)\n",
    "    ax2.axvline(x=1.25, ymin=0.0, ymax=1.0, color='r')\n",
    "    ax2.set(xlabel=param_labels[0], title='Cluster ' + str(j+1)+ \", loc. 2\")\n",
    "    ax2.set_ylabel('Density')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    vals = params[idx].flat[:]\n",
    "    ax1.hist(vals, bins=20, range=(param_range[0, 0], param_range[0, 1]))\n",
    "    ax1.axvline(x=.65, ymin=0.0, ymax=1.0, color='r')    #xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    #ax1.plot(xs, GKDE(params[idx].flat[:])(xs), linewidth=2)\n",
    "    #ax1.axvline(x=.65, ymin=0.0, ymax=1.0, color='r')\n",
    "    ax1.set(xlabel=param_labels[0], title='Cluster ' + str(j+1) + \", loc. 1\")\n",
    "    #ax1.set_ylabel('Density')\n",
    "    \n",
    "    idx2 = np.where(learn2.predict_labels == j)[0]\n",
    "    vals2 = params[idx2].flat[:]\n",
    "    #xs = np.linspace(param_range[0, 0], param_range[0, 1], 100)\n",
    "    #ax2.plot(xs, GKDE(params[idx].flat[:])(xs), linewidth=2)\n",
    "    #ax2.axvline(x=1.25, ymin=0.0, ymax=1.0, color='r')\n",
    "    ax2.set(xlabel=param_labels[0], title='Cluster ' + str(j+1)+ \", loc. 2\")\n",
    "    #ax2.set_ylabel('Density')\n",
    "    ax2.hist(vals2, bins=20, range=(param_range[0, 0], param_range[0, 1]))\n",
    "    ax2.axvline(x=1.25, ymin=0.0, ymax=1.0, color='r')\n",
    "    #print(min(vals), max(vals))\n",
    "    print(min(vals2), max(vals2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "z = max(vals2)\n",
    "z = (z-0.75)/(3.0-0.75)\n",
    "p2 = beta.cdf(z, 2.0, 2.0)\n",
    "p1 = 1.0 - p2\n",
    "print(p1, p2)\n",
    "print(cluster_weights2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
