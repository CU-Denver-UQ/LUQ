{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019-2020 Steven Mattis and Troy Butler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as wd\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from scipy.integrate import quadrature as quad\n",
    "from scipy.stats import beta \n",
    "from math import *\n",
    "from luq.luq import *\n",
    "import luq.dynamical_systems as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams.update({'axes.linewidth': 2})\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the Sel'kov model for glycolysis, a process by which living cells breakdown sugar to obtain energy:\n",
    "$$x' = -(x+b) + a \\left(y + \\frac{b}{a+b^2} \\right) + (x+b)^2 \\left(y + \\frac{b}{a+b^2}\\right)$$\n",
    "$$y' = b-a\\left(y+ \\frac{b}{a+b^2}\\right) - (x+b)^2 \\left(y + \\frac{b}{a+b^2}\\right), $$\n",
    "where $x$ and $y$ represent concentrations of ADP and F6P, respectively, and $a,b>0$.\n",
    "The initial conditions are $x(0) = x_0 \\in \\mathbb{R}$ and $y(0) = y_0 \\in \\mathbb{R}$.\n",
    "\n",
    "The system has Hopf Bifurcations at \n",
    "$$b = b_1(a) = \\sqrt{(1-\\sqrt{1-8a}-2a)/2}$$\n",
    "and\n",
    "$$b = b_2(a) = \\sqrt{(1+\\sqrt{1-8a}-2a)/2}.$$\n",
    "If $b<b_1$, the origin is a stable focus. If $b_1 < b < b_2$, there is a stable periodic orbit.\n",
    "If $b > b_2$ the origin is a stable focus.\n",
    "\n",
    "The system is solved numerically using the RK45 method.\n",
    "\n",
    "A ***true*** distribution of $a, b,  x_0$, and $y_0$ are defined by (non-uniform)\n",
    "Beta distributions and used to generate a set of time series data.\n",
    "\n",
    "An ***initial*** uniform distribution is assumed and updated by the true time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample the parameter samples to form a \"prediction\" or \"test\" set\n",
    "num_samples = int(3E3)\n",
    "\n",
    "param_range = np.array([[0.01, 0.124], # a\n",
    "                       [0.05, 1.5]])  #b\n",
    "ic_range = np.array([[1.0, 1.0],  # y_0\n",
    "                     [1.0, 1.0]])  # x_0\n",
    "\n",
    "params = np.random.uniform(size=(num_samples, 2))\n",
    "params = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params\n",
    "\n",
    "ics = np.random.uniform(size=(num_samples, 2))\n",
    "ics = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics\n",
    "\n",
    "# labels\n",
    "param_labels = [r'$a$', r'$b$']\n",
    "ic_labels = [r'$x_0$', r'$y_0$']\n",
    "\n",
    "# Construct the predicted time series data\n",
    "time_start = 2.0 #0.5\n",
    "time_end = 6.5 #40.0\n",
    "num_time_preds = int((time_end-time_start)*100)  # number of predictions (uniformly space) between [time_start,time_end]\n",
    "times = np.linspace(time_start, time_end, num_time_preds)\n",
    "\n",
    "# Solve systems\n",
    "phys = ds.Selkov()\n",
    "predicted_time_series = phys.solve(ics=ics, params=params, t_eval=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate an observed Beta distribution of time series data\n",
    "\n",
    "num_obs = int(5E2)\n",
    "\n",
    "true_a = 2\n",
    "true_b = 2\n",
    "\n",
    "params_obs = np.random.beta(size=(num_obs, 2), a=true_a, b=true_b)\n",
    "params_obs = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params_obs\n",
    "\n",
    "ics_obs = np.random.beta(size=(num_obs, 2), a=true_a, b=true_b)\n",
    "ics_obs = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics_obs\n",
    "\n",
    "# Solve system\n",
    "observed_time_series = phys.solve(ics=ics_obs, params=params_obs, t_eval=times)\n",
    "\n",
    "# Add noise if desired\n",
    "with_noise = True\n",
    "noise_stdev = 0.0125\n",
    "\n",
    "if with_noise:\n",
    "    observed_time_series += noise_stdev * np.random.randn(num_obs, times.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use LUQ to learn dynamics and QoIs\n",
    "learn = LUQ_temporal(predicted_time_series, observed_time_series, times)\n",
    "\n",
    "# time array indices over which to use\n",
    "time_start_idx = 0\n",
    "time_end_idx = len(times) - 1#150 #120\n",
    "\n",
    "# Filter data\n",
    "learn.filter_data(time_start_idx=time_start_idx, time_end_idx=time_end_idx,\n",
    "                 num_filtered_obs=20, tol=5.0e-2, min_knots=3, max_knots=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn and classify dynamics\n",
    "learn.dynamics(cluster_method='kmeans', kwargs={'n_clusters': 3, 'n_init': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "# chosen_obs = [109, 8]\n",
    "\n",
    "chosen_obs = [0, 1, 499]  #7]\n",
    "colors = ['r', 'g', 'b']\n",
    "\n",
    "for i, c in zip(chosen_obs,colors):\n",
    "    plt.plot(learn.times[time_start_idx:time_end_idx+1], learn.observed_time_series[i,time_start_idx:time_end_idx+1],color=c, linestyle='none', marker='.', markersize=10, alpha=0.25)\n",
    "    \n",
    "for i in chosen_obs:\n",
    "    num_i_knots = int(0.5*(2+len(learn.obs_knots[i])))\n",
    "    knots = np.copy(learn.obs_knots[i][num_i_knots:])\n",
    "    knots = np.insert(knots, 0, learn.filtered_times[0])\n",
    "    knots = np.append(knots, learn.filtered_times[-1])\n",
    "    plt.plot(knots, learn.obs_knots[i][:num_i_knots], 'k', linestyle='dashed', markersize=15, marker='o', linewidth=2)\n",
    "    \n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$x(t)$')\n",
    "plt.title('Approximating Dynamics') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for i, c in zip(chosen_obs,colors):\n",
    "    plt.plot(learn.times[time_start_idx:time_end_idx+1], learn.observed_time_series[i,time_start_idx:time_end_idx+1],color=c, linestyle='none', marker='.', markersize=10, alpha=0.25)\n",
    "    \n",
    "for i in chosen_obs:\n",
    "    plt.plot(learn.filtered_times, learn.filtered_obs[i,:],'k', linestyle='none', marker='s', \n",
    "            markersize=12)\n",
    "    \n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$x(t)$')\n",
    "plt.title('Generating Clean Data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot clusters of predicted time series\n",
    "num_filtered_obs = learn.filtered_times.shape[0]\n",
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]}) \n",
    "    ax1.scatter(np.tile(learn.filtered_times,num_samples).reshape(num_samples, num_filtered_obs), \n",
    "                learn.filtered_predictions, 50, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    ax1.scatter(np.tile(learn.filtered_times,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn.filtered_predictions[idx,:], 50, c='b', marker='o', alpha=0.2)\n",
    "    idx2 = np.where(learn.obs_labels == j)[0]    \n",
    "    ax1.scatter(np.tile(learn.filtered_times,len(idx2)).reshape(len(idx2),num_filtered_obs), \n",
    "                learn.filtered_obs[idx2, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    ax1.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "    ax1.set_xlabel('$t$')\n",
    "    ax1.set_ylabel('$x(t)$')\n",
    "    \n",
    "    ax2.scatter(params[:,0], params[:,1], 30, c='gray', marker='.', alpha=0.2)\n",
    "    ax2.scatter(params[idx,0], params[idx,1], 50, c='blue', marker='o')\n",
    "    ax2.set(title='Cluster ' + str(j+1) + ' in parameters')\n",
    "    ax2.set_ylabel(param_labels[1])\n",
    "    ax2.set_xlabel(param_labels[0])\n",
    "    xs = np.linspace(param_range[0,0], param_range[0,1], 100)\n",
    "    ys1 = np.sqrt(0.5*(1.0 - np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "    ys2 = np.sqrt(0.5*(1.0 + np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "    ax2.plot(xs, ys1, 'r-', linewidth=3)\n",
    "    ax2.plot(xs, ys2, 'r-', linewidth=3)\n",
    "    fig.tight_layout\n",
    "# for j in range(learn.num_clusters):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,8), gridspec_kw={'width_ratios': [1, 1]}) \n",
    "#     ps = []\n",
    "#     idx = np.where(learn.predict_labels == j)[0]\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == j:\n",
    "#             ps.append(params[i,0]/params[i,1])\n",
    "#             ax1.scatter(learn.filtered_times, learn.filtered_predictions[i,:], 50, c='b', marker='o', alpha=0.2)\n",
    "#         else:\n",
    "#             ax1.scatter(learn.filtered_times, learn.filtered_predictions[i,:], 50, c='gray', marker='.', alpha=0.2)\n",
    "#     ax1.set(title='Cluster ' + str(j+1) + ' in data')\n",
    "#     ax1.set_xlabel('$t$')\n",
    "#     ax1.set_ylabel('$y(t)$')\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == j:\n",
    "#             ax2.scatter(params[i,0], params[i,1], 50, c='blue', marker='o')\n",
    "#         else:\n",
    "#             ax2.scatter(params[i,0], params[i,1], 30, c='gray', marker='.', alpha=0.2)\n",
    "#     ax2.set(title='Cluster ' + str(j+1) + ' in parameters')\n",
    "#     ax2.set_ylabel(param_labels[1])\n",
    "#     ax2.set_xlabel(param_labels[0])\n",
    "#     xs = np.linspace(param_range[0,0], param_range[0,1], 100)\n",
    "#     ys1 = np.sqrt(0.5*(1.0 - np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ys2 = np.sqrt(0.5*(1.0 + np.sqrt(1.0 - 8.0*xs) -2.0*xs))\n",
    "#     ax2.plot(xs, ys1, 'r-')\n",
    "#     ax2.plot(xs, ys2, 'r-')\n",
    "#     fig.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Plot oberved and predicted clusters\n",
    "\n",
    "for j in range(learn.num_clusters):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.scatter(np.tile(learn.filtered_times,num_samples).reshape(num_samples,num_filtered_obs), \n",
    "                learn.filtered_predictions, 10, c='gray', marker='.', alpha=0.2)\n",
    "    idx = np.where(learn.predict_labels == j)[0]\n",
    "    plt.scatter(np.tile(learn.filtered_times,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn.filtered_predictions[idx,:], 20, c='b', marker='o', alpha=0.3)\n",
    "    idx = np.where(learn.obs_labels == j)[0]    \n",
    "    plt.scatter(np.tile(learn.filtered_times,len(idx)).reshape(len(idx),num_filtered_obs), \n",
    "                learn.filtered_obs[idx, :], 50, c='r', marker='s', alpha=0.2)\n",
    "    plt.title('Classifying cleaned observations')\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$x(t)$')\n",
    "    bottom, top = plt.gca().get_ylim()\n",
    "    left, right = plt.gca().get_xlim()\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "    plt.text(right-1, top-0.2, \n",
    "             'Cluster ' + str(j+1), \n",
    "             {'color': 'k', 'fontsize': 20},\n",
    "             bbox=props)\n",
    "    plt.text\n",
    "    fig.tight_layout\n",
    "\n",
    "# for j in range(learn.num_clusters):\n",
    "#     fig = plt.figure(figsize=(10,8))\n",
    "#     ps = []\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == j:\n",
    "#             ps.append(params[i,0]/params[i,1])\n",
    "#             plt.scatter(learn.filtered_times, learn.filtered_predictions[i,:], 50, c='b', marker='.', alpha=0.2)\n",
    "#         else:\n",
    "#             plt.scatter(learn.filtered_times, learn.filtered_predictions[i,:], 20, c='gray', marker='.', alpha=0.2)\n",
    "#     for i in range(num_obs):        \n",
    "#         if learn.obs_labels[i] == j:\n",
    "#             plt.scatter(learn.filtered_times, learn.filtered_obs[i, :], 50, c='r', marker='o', alpha=0.2)\n",
    "#     plt.title('Classifying cleaned observations')\n",
    "#     plt.xlabel('$t$')\n",
    "#     plt.ylabel('$y(t)$')\n",
    "#     bottom, top = plt.gca().get_ylim()\n",
    "#     left, right = plt.gca().get_xlim()\n",
    "#     props = dict(boxstyle='round', facecolor='gray', alpha=0.2)\n",
    "#     plt.text(right-1, top-0.2, \n",
    "#              'Cluster ' + str(j+1), \n",
    "#              {'color': 'k', 'fontsize': 20},\n",
    "#              bbox=props)\n",
    "#     plt.text\n",
    "#     fig.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot clusters of predicted time series\n",
    "# for j in range(learn.num_clusters):\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,2.5), \n",
    "#                                         gridspec_kw={'width_ratios': [3,1,1]}) \n",
    "#     ps = []\n",
    "#     ps2 = []\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == j:\n",
    "#             a = params[i, 0]\n",
    "#             b = params[i, 1]\n",
    "#             b1 = sqrt((1.0-sqrt(1.-8.*a)-2.*a)/2.0)\n",
    "#             b2 = sqrt((1.0+sqrt(1.-8.*a)-2.*a)/2.0)\n",
    "#             ps.append(b/b1)\n",
    "#             ps2.append(b/b2)\n",
    "#             ax1.plot(learn.filtered_times, learn.filtered_predictions[i, :])\n",
    "#     ax1.set(title='Cluster ' + str(j))\n",
    "#     xs = np.linspace(0.0, 5.0, 100)\n",
    "#     ax2.plot(xs, GKDE(ps)(xs))\n",
    "#     ax2.axvline(1.0, color='r')\n",
    "#     ax2.set(xlabel=r'$b/b_1$', title='Param. Distrib.')\n",
    "#     xs2 = np.linspace(0.0, 2.0, 100)\n",
    "#     ax3.plot(xs2, GKDE(ps2)(xs2))\n",
    "#     ax3.axvline(1.0, color='r')\n",
    "#     ax3.set(xlabel=r'$b/b_2$', title='Param. Distrib.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot oberved and predicted clusters\n",
    "# for j in range(learn.num_clusters):\n",
    "#     plt.figure()\n",
    "#     cluster_num = j\n",
    "#     for i in range(num_samples):\n",
    "#         if learn.predict_labels[i] == cluster_num:\n",
    "#             plt.plot(learn.filtered_times, learn.filtered_predictions[i,:],'b*')\n",
    "#     for i in range(num_obs):\n",
    "#         if learn.obs_labels[i] == cluster_num:\n",
    "#             plt.plot(learn.filtered_times, learn.filtered_obs[i,:],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best KPCA transformation for given number of QoI and transform time series data.\n",
    "predict_map, obs_map = learn.learn_qois_and_transform(num_qoi=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "\n",
    "def plot_gap(all_eig_vals, n, cluster):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    #Plotting until maximum number of knots\n",
    "    eig_vals = all_eig_vals[cluster].eigenvalues_[0:10]\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals/np.sum(eig_vals)*100, marker='.', markersize=20, linestyle='')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'k--')\n",
    "    plt.semilogy(np.arange(np.size(eig_vals))+1,eig_vals[n+1]/np.sum(eig_vals)*100*np.ones(np.size(eig_vals)), 'r--')\n",
    "    plt.text(n+1, eig_vals[n]/np.sum(eig_vals)*150, \n",
    "             r'%2.3f' %(np.sum(eig_vals[0:n+1])/np.sum(eig_vals)*100) + '% of variation explained by first ' + '%1d' %(n+1) + ' PCs.', \n",
    "                                                               {'color': 'k', 'fontsize': 20})\n",
    "    plt.text(n+2, eig_vals[n+1]/np.sum(eig_vals)*150, \n",
    "             r'Order of magnitude of gap is %4.2f.' %(np.log10(eig_vals[n])-np.log10(eig_vals[n+1])), \n",
    "                                                               {'color': 'r', 'fontsize': 20})\n",
    "    s = 'Determining QoI for cluster #%1d' %(cluster+1)\n",
    "    plt.title(s)\n",
    "    plt.xlabel('Principal Component #')\n",
    "    plt.ylabel('% of Variation')\n",
    "    plt.xlim([0.1, np.size(eig_vals)+1])\n",
    "    plt.ylim([1e-5,500])\n",
    "\n",
    "\n",
    "wd.interact(plot_gap, all_eig_vals=wd.fixed(learn.kpcas),\n",
    "            n = wd.IntSlider(value=0, min=0, max=5),\n",
    "            cluster = wd.IntSlider(value=0, min=0, max=learn.num_clusters-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate kernel density estimates on new QoI and calculate new weights\n",
    "pi_predict_kdes = []\n",
    "pi_obs_kdes = []\n",
    "r_vals = []\n",
    "r_means = []\n",
    "for i in range(learn.num_clusters):\n",
    "    pi_predict_kdes.append(GKDE(learn.predict_maps[i].T))\n",
    "    pi_obs_kdes.append(GKDE(learn.obs_maps[i].T))\n",
    "    r_vals.append(\n",
    "        np.divide(\n",
    "            pi_obs_kdes[i](\n",
    "                learn.predict_maps[i].T), \n",
    "            pi_predict_kdes[i](\n",
    "                learn.predict_maps[i].T)))\n",
    "    r_means.append(np.mean(r_vals[i]))\n",
    "print(f'Diagnostics: {r_means}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute marginal probablities for each parameter and initial condition.\n",
    "param_marginals = []\n",
    "ic_marginals = []\n",
    "true_param_marginals = []\n",
    "true_ic_marginals = []\n",
    "lam_ptr = []\n",
    "cluster_weights = []\n",
    "for i in range(learn.num_clusters):\n",
    "    lam_ptr.append(np.where(learn.predict_labels == i)[0])\n",
    "    cluster_weights.append(len(np.where(learn.obs_labels == i)[0]) / num_obs)\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    true_param_marginals.append(GKDE(params_obs[:,i]))\n",
    "    param_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        param_marginals[i].append(GKDE(params[lam_ptr[j], i], weights=r_vals[j]))\n",
    "        \n",
    "##for i in range(ics.shape[1]):\n",
    "#    true_ic_marginals.append(GKDE(ics_obs[:,i]))\n",
    "#    ic_marginals.append([])\n",
    "#    for j in range(learn.num_clusters):\n",
    "#        ic_marginals[i].append(GKDE(ics[lam_ptr[j], i], weights=r_vals[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform distribution\n",
    "def unif_dist(x, p_range):\n",
    "    y = np.zeros(x.shape)\n",
    "    val = 1.0/(p_range[1] - p_range[0])\n",
    "    for i, xi in enumerate(x):\n",
    "        if xi < p_range[0] or xi >  p_range[1]:\n",
    "            y[i] = 0\n",
    "        else:\n",
    "            y[i] = val\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted marginal densities for parameters\n",
    "\n",
    "for i in range(params.shape[1]):  \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(params[:, i]), min(params_obs[:, i]))\n",
    "    x_max = max(max(params[:, i]), max(params_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, param_range[i, :]),\n",
    "         label = 'Initial', linewidth=4)\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Updated', linewidth=4, linestyle='dashed')\n",
    "    plt.plot(x, true_param_marginals[i](x), label = 'Data-generating', \n",
    "             linewidth=4, linestyle='dotted')\n",
    "    plt.title('Densities for parameter ' + param_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)\n",
    "    if i == 0:\n",
    "        plt.xticks([0, 0.05, 0.1, 0.15])\n",
    "    else:\n",
    "        plt.xticks([0, 0.5, 1., 1.5])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot predicted marginal densities for initial conditions.\n",
    "\n",
    "# for i in range(ics.shape[1]):\n",
    "#     fig = plt.figure(figsize=(10,10))\n",
    "#     fig.clear()\n",
    "#     x_min = min(min(ics[:, i]), min(ics_obs[:, i]))\n",
    "#     x_max = max(max(ics[:, i]), max(ics_obs[:, i]))\n",
    "#     delt = 0.25*(x_max - x_min)\n",
    "#     x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "#     plt.plot(x, unif_dist(x, ic_range[i, :]),\n",
    "#          label = 'Initial guess')\n",
    "#     mar = np.zeros(x.shape)\n",
    "#     for j in range(learn.num_clusters):\n",
    "#         mar += ic_marginals[i][j](x) * cluster_weights[j]\n",
    "#     plt.plot(x, mar, label = 'Estimated pullback')\n",
    "#     plt.plot(x, true_ic_marginals[i](x), label = 'Actual density')\n",
    "#     plt.title('Comparing pullback to actual density of initial condition ' + ic_labels[i], fontsize=16)\n",
    "#     plt.legend(fontsize=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TV metric between densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_init_error(x):\n",
    "    return np.abs(unif_dist(x,param_range[param_num, :])-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(param_init_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def param_update_KDE_error(x):\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[param_num][j](x) * cluster_weights[j]\n",
    "    return np.abs(mar-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(param_update_KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDE_error(x):\n",
    "    true_beta = beta(a=true_a, b=true_b,loc=param_range[i,0],scale=param_range[i,1]-param_range[i,0])\n",
    "    return np.abs(true_beta.pdf(x)-true_param_marginals[param_num](x))\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    param_num=i\n",
    "    TV_metric = quad(KDE_error,param_range[i,0],param_range[i,1],maxiter=1000)\n",
    "    print(TV_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
