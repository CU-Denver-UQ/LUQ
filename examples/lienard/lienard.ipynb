{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 Steven Mattis and Troy Butler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from luq.luq import *\n",
    "import luq.dynamical_systems as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the LiÃ©nard system, a second order ODE system, which models oscillating circuits:\n",
    "    $$ u' = v $$\n",
    "    $$ v' = -u + (\\mu - u^2) v. $$\n",
    "    \n",
    "The initial conditions are given by $u(0) = u_0 \\in \\mathbb{R}$ and \n",
    "$v(0) = v_0 \\in \\mathbb{R}$.\n",
    "\n",
    "The system has a supercritical Hopf bifurcation at $\\mu = 0$. There is a \n",
    "stable periodic orbit for $\\mu > 0$ and the origin is a stable focus for $\\mu < 0$. \n",
    "See https://www.math.colostate.edu/~shipman/47/volume3b2011/M640_MunozAlicea.pdf \n",
    "    for more details.\n",
    "    \n",
    "The system is solved numerically using the RK45 method.\n",
    "\n",
    "A ***true*** distribution of $\\mu, u_0$, and $v_0$ are defined by (non-uniform)\n",
    "Beta distributions and used to generate a set of time series data.\n",
    "\n",
    "An ***initial*** uniform distribution is assumed and updated by the true time series data.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample the parameter samples to form a \"prediction\" or \"test\" set\n",
    "num_samples = int(1e3)\n",
    "\n",
    "params = np.random.uniform(size=(num_samples, 1))\n",
    "param_range = np.array([[-0.5, 0.5]]) # range for nu\n",
    "\n",
    "ics = np.random.uniform(size=(num_samples, 2))\n",
    "ic_range = np.array([[0.1, 0.5], [-0.5, -0.1]]) # range for u_0 and v_0  \n",
    "\n",
    "params = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params\n",
    "ics = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics\n",
    "\n",
    "# labels\n",
    "param_labels = [r'$\\mu$']\n",
    "ic_labels = [r'$u_0$', r'$v_0$']\n",
    "\n",
    "\n",
    "# Construct the predicted time series data\n",
    "num_time_preds = int(500)  # number of predictions (uniformly spaced) between [time_start,time_end]\n",
    "time_start = 0.5\n",
    "time_end = 40.0\n",
    "times = np.linspace(time_start, time_end, num_time_preds)\n",
    "\n",
    "# Solve systems\n",
    "phys = ds.Lienard()\n",
    "predicted_time_series = phys.solve(ics=ics, params=params, t_eval=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate an observed Beta distribution of time series data\n",
    "num_obs = int(1e3)\n",
    "\n",
    "true_a = 2\n",
    "true_b = 2\n",
    "\n",
    "params_obs = np.random.beta(size=(num_obs, 1), a=true_a, b=true_b)\n",
    "ics_obs = np.random.beta(size=(num_obs, 2), a=true_a, b=true_b) \n",
    "\n",
    "params_obs = param_range[:, 0] + (param_range[:, 1] - param_range[:, 0]) * params_obs\n",
    "ics_obs = ic_range[:, 0] + (ic_range[:, 1] - ic_range[:, 0]) * ics_obs\n",
    "\n",
    "# Solve systems\n",
    "observed_time_series = phys.solve(ics=ics_obs, params=params_obs, t_eval=times)\n",
    "\n",
    "# Add noise if desired\n",
    "with_noise = False\n",
    "noise_stdev = 0.05\n",
    "\n",
    "if with_noise:\n",
    "    observed_time_series += noise_stdev * np.random.randn(num_obs, times.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use LUQ to learn dynamics and QoIs\n",
    "learn = LUQ(predicted_data=predicted_time_series, \n",
    "            observed_data=observed_time_series)\n",
    "\n",
    "# time array indices over which to use\n",
    "time_start_idx = 350\n",
    "time_end_idx = 499\n",
    "\n",
    "num_filtered_obs = 50\n",
    "\n",
    "filtered_times = np.linspace(times[time_start_idx],\n",
    "                             times[time_end_idx],\n",
    "                             num_filtered_obs)                          \n",
    "\n",
    "# Filter data with piecewise linear splines\n",
    "learn.filter_data(filter_method='splines',\n",
    "                  predicted_data_coordinates=times,\n",
    "                  observed_data_coordinates=times,\n",
    "                  filtered_data_coordinates=filtered_times,\n",
    "                  tol=3.0e-2, \n",
    "                  min_knots=15, \n",
    "                  max_knots=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn and classify dynamics.\n",
    "learn.dynamics(cluster_method='kmeans', kwargs={'n_clusters': 2, 'n_init': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters of predicted time series\n",
    "for j in range(learn.num_clusters):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2.5), gridspec_kw={'width_ratios': [3, 1]}) #(figsize=(10,5))\n",
    "    ps = []\n",
    "    for i in range(num_samples):\n",
    "        if learn.predict_labels[i] == j:\n",
    "            ps.append(params[i,0])\n",
    "            ax1.plot(learn.filtered_data_coordinates, learn.filtered_predictions[i, :])\n",
    "    ax1.set(title='Cluster ' + str(j))\n",
    "    xs = np.linspace(param_range[0, 0], param_range[0,1], 100)\n",
    "    ax2.plot(xs, GKDE(ps)(xs))\n",
    "    ax2.set(xlabel=param_labels[0], title='Param. Distrib.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed and predicted clusters\n",
    "for j in range(learn.num_clusters):\n",
    "    plt.figure()\n",
    "    cluster_num = j\n",
    "    for i in range(num_samples):\n",
    "        if learn.predict_labels[i] == cluster_num:\n",
    "            plt.plot(learn.filtered_data_coordinates, learn.filtered_predictions[i,:],'b*')\n",
    "    for i in range(num_obs):\n",
    "        if learn.obs_labels[i] == cluster_num:\n",
    "            plt.plot(learn.filtered_data_coordinates, learn.filtered_obs[i,:],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best KPCA transformation for given number of QoI and transform time series data.\n",
    "predict_map, obs_map = learn.learn_qois_and_transform(num_qoi=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate kernel density estimates on new QoI and calculate new weights\n",
    "pi_predict_kdes = []\n",
    "pi_obs_kdes = []\n",
    "r_vals = []\n",
    "r_means = []\n",
    "for i in range(learn.num_clusters):\n",
    "    pi_predict_kdes.append(GKDE(learn.predict_maps[i].T))\n",
    "    pi_obs_kdes.append(GKDE(learn.obs_maps[i].T))\n",
    "    r_vals.append(\n",
    "        np.divide(\n",
    "            pi_obs_kdes[i](\n",
    "                learn.predict_maps[i].T), \n",
    "            pi_predict_kdes[i](\n",
    "                learn.predict_maps[i].T)))\n",
    "    r_means.append(np.mean(r_vals[i]))\n",
    "print(f'Diagnostics: {r_means}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute marginal probablities for each parameter and initial condition.\n",
    "param_marginals = []\n",
    "ic_marginals = []\n",
    "true_param_marginals = []\n",
    "true_ic_marginals = []\n",
    "lam_ptr = []\n",
    "cluster_weights = []\n",
    "for i in range(learn.num_clusters):\n",
    "    lam_ptr.append(np.where(learn.predict_labels == i)[0])\n",
    "    cluster_weights.append(len(np.where(learn.obs_labels == i)[0]) / num_obs)\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    true_param_marginals.append(GKDE(params_obs[:,i]))\n",
    "    param_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        param_marginals[i].append(GKDE(params[lam_ptr[j], i], weights=r_vals[j]))\n",
    "        \n",
    "for i in range(ics.shape[1]):\n",
    "    true_ic_marginals.append(GKDE(ics_obs[:,i]))\n",
    "    ic_marginals.append([])\n",
    "    for j in range(learn.num_clusters):\n",
    "        ic_marginals[i].append(GKDE(ics[lam_ptr[j], i], weights=r_vals[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform distribution\n",
    "def unif_dist(x, p_range):\n",
    "    y = np.zeros(x.shape)\n",
    "    val = 1.0/(p_range[1] - p_range[0])\n",
    "    for i, xi in enumerate(x):\n",
    "        if xi < p_range[0] or xi >  p_range[1]:\n",
    "            y[i] = 0\n",
    "        else:\n",
    "            y[i] = val\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted marginal densities for parameters\n",
    "\n",
    "for i in range(params.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(params[:, i]), min(params_obs[:, i]))\n",
    "    x_max = max(max(params[:, i]), max(params_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, param_range[i, :]),\n",
    "         label = 'Initial guess')\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += param_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Estimated pullback')\n",
    "    plt.plot(x, true_param_marginals[i](x), label = 'Actual density')\n",
    "    plt.title('Comparing pullback to actual density of parameter ' + param_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted marginal densities for initial conditions.\n",
    "\n",
    "for i in range(ics.shape[1]):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.clear()\n",
    "    x_min = min(min(ics[:, i]), min(ics_obs[:, i]))\n",
    "    x_max = max(max(ics[:, i]), max(ics_obs[:, i]))\n",
    "    delt = 0.25*(x_max - x_min)\n",
    "    x = np.linspace(x_min-delt, x_max+delt, 100)\n",
    "    plt.plot(x, unif_dist(x, ic_range[i, :]),\n",
    "         label = 'Initial guess')\n",
    "    mar = np.zeros(x.shape)\n",
    "    for j in range(learn.num_clusters):\n",
    "        mar += ic_marginals[i][j](x) * cluster_weights[j]\n",
    "    plt.plot(x, mar, label = 'Estimated pullback')\n",
    "    plt.plot(x, true_ic_marginals[i](x), label = 'Actual density')\n",
    "    plt.title('Comparing pullback to actual density of initial condition ' + ic_labels[i], fontsize=16)\n",
    "    plt.legend(fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
