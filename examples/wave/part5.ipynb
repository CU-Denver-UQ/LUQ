{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c05d5f-08e1-430b-b6e5-efb48ea74f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from luq.luq import *\n",
    "from scipy.stats import norm, beta\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from scipy.integrate import quadrature\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import ipywidgets as wd\n",
    "\n",
    "# colorblind friendly color palette\n",
    "c = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# setup fontsizes for plots\n",
    "plt_params = {'legend.fontsize': 14,\n",
    "          'figure.figsize': (10,8), #(6.4, 4.8),\n",
    "         'axes.labelsize': 16,\n",
    "         'axes.titlesize': 16,\n",
    "         'xtick.labelsize': 14,\n",
    "         'ytick.labelsize': 14}\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626215cf-46fd-45a1-9f65-88744b81718e",
   "metadata": {},
   "source": [
    "# Details on Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2454eb1-9b6e-4c9f-bee9-ced9fa7fffc3",
   "metadata": {},
   "source": [
    "Data was created in the notebook/script labeled 'generating_data' found with this notebook. The model is the 2-D wave equation $$\\dfrac{\\partial^2 u}{\\partial t^2}=\\dfrac{\\partial^2 u}{\\partial x^2}+\\dfrac{\\partial^2 u}{\\partial y^2}, \\quad \\left(x,y\\right)\\in (0,5)^2$$ with $u=u(x,y,t)$ and boundary conditions $u(0,y,t)=u(x,0,t)=u(5,y,t)=u(x,5,t)=0$. The problem is to model a water droplet at location $(a,b)$ given by $$u(x,y,0)=0.2\\text{exp}\\left(-10\\left(\\left(x-a\\right)^2+\\left(y-b\\right)^2\\right)\\right)$$ where the location $(a,b)$ has some unknown distribution creating uncertain model outputs, and the goal is to quantify the uncertainty in the droplet locations using observed uncertainties in model outputs. In this example, we explore how much spatial data is sufficient to learn QoI maps via kernel PCA. The candidate data is generated by creating 1000 i.i.d. uniform samples of $[0,5]^2$ and solving the model using a standard centered finite difference scheme on a 101x101 regular uniformly-spaced mesh on $[0,5]^2$ using 0.005 sized time-steps. The data is then extracted over varying sub-grid sizes (excluding boundaries) of 99x99 with $dx=dy=0.05$, 49x49 with $dx=dy=0.1$, 19x19 with $dx=dy=0.25$, 9x9 with $dx=dy=0.5$, and 4x4 with $dx=dy=1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47453f-084e-4045-a681-226ad75611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "preds = []\n",
    "pred_grids = []\n",
    "for i in range(20):\n",
    "    delta = 0.05 * (i+1)\n",
    "    N = (5 - delta) / delta\n",
    "    if N == int(N):\n",
    "        fn = 'data/pred_' + str(int(N)) + 'x' + str(int(N))\n",
    "        preds.append(np.load(fn, allow_pickle=True))\n",
    "        pred_grids.append(str(int(N)) + 'x' + str(int(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b28b74-8822-42e9-8f7a-6afba4904b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different grid sizes\n",
    "\n",
    "print('Different grid sizes used:')\n",
    "print()\n",
    "for grid in pred_grids:\n",
    "    print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f2db3-4b43-4343-a486-77cc67a335fa",
   "metadata": {},
   "source": [
    "# Compute Normalized Alpha Vectors from Kernel PCA Using LUQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3b3c5-0ae1-49d8-b586-d7e42e884d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning QoI over each grid; same setup as part 3 but with different grid sizes\n",
    "\n",
    "LUQs = []\n",
    "for i, pred in enumerate(preds):\n",
    "    LUQs.append(LUQ(pred[:,:,9]))\n",
    "    LUQs[i].learn_qois_and_transform(num_qoi=2)\n",
    "    \n",
    "# normalize eigenvectors\n",
    "unit_alphas = []\n",
    "for i in range(len(preds)):\n",
    "    unit_alphas.append([])\n",
    "    for j in range(2):\n",
    "        unit_alphas[i].append(LUQs[i].kpcas[0].eigenvectors_[:,j] / np.linalg.norm(LUQs[i].kpcas[0].eigenvectors_[:,j], ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6d92b-e684-4faf-8491-147f8e525162",
   "metadata": {},
   "source": [
    "# Comparing Alpha Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddeecf-229b-4063-a9c3-6cffd4930af0",
   "metadata": {},
   "source": [
    "## Linear Regression Diagnostics on Alpha Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb73aaf-e948-494f-b4a1-350f5243e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying linear regression for each grid pair\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "As = []\n",
    "ms = []\n",
    "bs = []\n",
    "R_squared = []\n",
    "for i in range(len(preds)-1):\n",
    "    As.append([])\n",
    "    ms.append([])\n",
    "    bs.append([])\n",
    "    R_squared.append([])\n",
    "    for j in range(2):\n",
    "        As[i].append(np.ones((preds[i].shape[0],2)))\n",
    "        As[i][j][:,1] = unit_alphas[-(i+1)][j]\n",
    "        coeffs, res, _, _ = lstsq(As[i][j], unit_alphas[-(i+2)][j])\n",
    "        ms[i].append(coeffs[1])\n",
    "        bs[i].append(coeffs[0])\n",
    "        SS_tot = np.sum((unit_alphas[-(i+1)][j] - np.mean(unit_alphas[-(i+2)][j]))**2)\n",
    "        R_squared[i].append(1-res/SS_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71614f61-763a-4c63-936a-31f267b3eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing diagnostics\n",
    "spacing = '     '\n",
    "for i in range(len(pred_grids)-1):\n",
    "    print(f'Results between grids {pred_grids[-(i+1)]} and {pred_grids[-(i+2)]}:')\n",
    "    for j in range(2):\n",
    "        print(spacing+f'QoI component {j+1}:')\n",
    "        print(2*spacing+f'slope: {ms[i][j]}')\n",
    "        print(2*spacing+f'R^2: {R_squared[i][j]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495d698-360a-48b4-873d-b20d60351003",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d75361-be06-4968-a92e-e51be9993389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting kpca components per grid\n",
    "\n",
    "m = []\n",
    "M = []\n",
    "Delta = []\n",
    "for i in range(2):\n",
    "    m.append(np.inf)\n",
    "    M.append(-np.inf)\n",
    "    for j in range(len(pred_grids)):\n",
    "        if unit_alphas[-(j+1)][i].min() < m[i]:\n",
    "            m[i] = unit_alphas[-(j+1)][i].min()\n",
    "        if unit_alphas[-(j+1)][i].max() > M[i]:\n",
    "            M[i] = unit_alphas[-(j+1)][i].max()\n",
    "    Delta.append(0.1 * (M[i] - m[i]))\n",
    "\n",
    "param_str = ['a', 'b']\n",
    "for i in range(len(pred_grids)-1):\n",
    "    for j in range(2):\n",
    "        plt.figure()\n",
    "        plt.scatter(unit_alphas[-(i+1)][j], unit_alphas[-(i+2)][j], c=c[0])\n",
    "        plt.xlim([m[j]-Delta[j],M[j]+Delta[j]])\n",
    "        plt.ylim([m[j]-Delta[j],M[j]+Delta[j]])\n",
    "        if j == 0:\n",
    "            component = r'$\\alpha^{(1)}$'\n",
    "        else:\n",
    "            component = r'$\\alpha^{(2)}$'\n",
    "        plt.xlabel(component + f' from {pred_grids[-(i+1)]} grid')\n",
    "        plt.ylabel(component + f' from {pred_grids[-(i+2)]} grid')\n",
    "        x = np.linspace(unit_alphas[-(i+1)][j].min(),\n",
    "                        unit_alphas[-(i+1)][j].max(),\n",
    "                        10000)\n",
    "        y = ms[i][j]*x+bs[i][j]\n",
    "        plt.plot(x, y, c=c[1], label=f'slope = {np.round(ms[i][j],3)}; '+r'$R^2$'+f' = {np.round(R_squared[i][j],3)}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "#         fn = 'plots/' + pred_grids[-(i+1)] + '_' + pred_grids[-(i+2)] + '_' + str(j+1) + '.png'\n",
    "#         plt.savefig(fn, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
