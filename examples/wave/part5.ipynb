{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c05d5f-08e1-430b-b6e5-efb48ea74f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from luq.luq import *\n",
    "from scipy.stats import norm, beta\n",
    "from scipy.stats import gaussian_kde as GKDE\n",
    "from scipy.integrate import quadrature\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import ipywidgets as wd\n",
    "\n",
    "# colorblind friendly color palette\n",
    "c = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "# setup fontsizes for plots\n",
    "plt_params = {'legend.fontsize': 14,\n",
    "          'figure.figsize': (10,8), #(6.4, 4.8),\n",
    "         'axes.labelsize': 16,\n",
    "         'axes.titlesize': 16,\n",
    "         'xtick.labelsize': 14,\n",
    "         'ytick.labelsize': 14}\n",
    "plt.rcParams.update(plt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626215cf-46fd-45a1-9f65-88744b81718e",
   "metadata": {},
   "source": [
    "# Details on Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2454eb1-9b6e-4c9f-bee9-ced9fa7fffc3",
   "metadata": {},
   "source": [
    "Data was created in the notebook/script labeled 'generating_data' found with this notebook. The model is the 2-D wave equation $$\\dfrac{\\partial^2 u}{\\partial t^2}=\\dfrac{\\partial^2 u}{\\partial x^2}+\\dfrac{\\partial^2 u}{\\partial y^2}, \\quad \\left(x,y\\right)\\in (0,5)^2$$ with $u=u(x,y,t)$ and boundary conditions $u(0,y,t)=u(x,0,t)=u(5,y,t)=u(x,5,t)=0$. The problem is to model a water droplet at location $(a,b)$ given by $$u(x,y,0)=0.2\\text{exp}\\left(-10\\left(\\left(x-a\\right)^2+\\left(y-b\\right)^2\\right)\\right)$$ where the location $(a,b)$ has some unknown distribution creating uncertain model outputs, and the goal is to quantify the uncertainty in the droplet locations using observed uncertainties in model outputs. In this example, we explore how much spatial data is sufficient to learn QoI maps via kernel PCA. The candidate data is generated by creating 1000 i.i.d. uniform samples of $[0,5]^2$ and solving the model using a standard centered finite difference scheme on a 101x101 regular uniformly-spaced mesh on $[0,5]^2$ using 0.005 sized time-steps. The data is then extracted over varying sub-grid sizes (excluding boundaries) of 99x99 with $dx=dy=0.05$, 49x49 with $dx=dy=0.1$, 19x19 with $dx=dy=0.25$, 9x9 with $dx=dy=0.5$, and 4x4 with $dx=dy=1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47453f-084e-4045-a681-226ad75611de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter samples of pi_init\n",
    "\n",
    "np.random.seed(123456)\n",
    "num_samples = int(1E3)\n",
    "params = np.random.uniform(low=0.0,high=5.0,size=(2,num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5954e-ae55-4851-a2c3-f427f129a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite-difference scheme\n",
    "\n",
    "# defining model solve function\n",
    "dx = 0.05\n",
    "dy = 0.05\n",
    "dt = 0.005 # satifies CFL condition\n",
    "\n",
    "xn = np.linspace(0,5.0,101) # 101 = length in x / dx\n",
    "ym = np.linspace(0,5.0,101)\n",
    "tk = np.linspace(0,7.0,1401) # 1401 = length in t / dt\n",
    "\n",
    "# defining model solve on 101x101 uniform mesh of [0,5]^2 for t = 0 to t = 7 with dt = 0.005\n",
    "def M(a,b):\n",
    "    # initializing the model solution\n",
    "    # using Dirichlet boundary conditions,so initializing with zeros means boundary values are set\n",
    "    u = np.zeros((101,101,1401))\n",
    "    \n",
    "    # iterate through times; t here is equivalent to time and time index\n",
    "    for t in range(1401):\n",
    "        \n",
    "        # if t = 0, use initial condition modeling wave droplet\n",
    "        if t == 0:\n",
    "            mesh = np.meshgrid(xn[1:-1],ym[1:-1])\n",
    "            u[1:-1,1:-1,t] = 0.2*np.exp(-10*((mesh[0].T-a)**2+(mesh[1].T-b)**2))\n",
    "        \n",
    "        # else solve model using finite-difference scheme\n",
    "        else:\n",
    "            u[1:-1,1:-1,t] = 2 * u[1:-1,1:-1,t-1] - u[1:-1,1:-1,max(0,t-2)] \\\n",
    "                + dt**2 / dx**2 * (u[2:,1:-1,t-1] - 2 * u[1:-1,1:-1,t-1] + u[:-2,1:-1,t-1]) \\\n",
    "                + dt**2 / dy**2 * (u[1:-1,2:,t-1] - 2 * u[1:-1,1:-1,t-1] + u[1:-1,:-2,t-1])\n",
    "    return u\n",
    "\n",
    "# indexing for extracting data on different grid sizes\n",
    "\n",
    "# indexing function for flattening data\n",
    "def idx_at(x,y):\n",
    "    idx = []\n",
    "    idx.append((x / dx).astype(int))\n",
    "    idx.append((y / dy).astype(int))\n",
    "    return idx\n",
    "\n",
    "# using indexing function to extract data on uniformly-spaced mesh given by delta\n",
    "def create_idx(delta):\n",
    "    N = (5-delta)/delta \n",
    "    # note: only delta such that (5-delta)/delta is int can be used (or does not change value when cast as int) \n",
    "    # any other delta value requires extrapolation\n",
    "    pts = np.linspace(delta,5-delta,int(N))\n",
    "    grid_pts = np.meshgrid(pts,pts)\n",
    "    idx = idx_at(grid_pts[0],grid_pts[1])\n",
    "    return [idx[0].flatten(), idx[1].flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd54bd6-5761-4f63-8c90-0e0df452434b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# solving model on full grid\n",
    "\n",
    "full_grid = np.zeros((num_samples,101,101,14))\n",
    "for i in range(num_samples):\n",
    "    tmp = M(params[0,i],params[1,i])\n",
    "    full_grid[i,:,:,:] = tmp[:,:,100::100]\n",
    "    print(f'sample {i} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04284787-0174-438e-855f-2a3e518b28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "pred_grids = []\n",
    "# extracting model solve on coarser grids\n",
    "for i in range(20):\n",
    "    delta = 0.05 * (i+1)\n",
    "    N = (5-delta)/delta\n",
    "    \n",
    "    # check if grid is subset of full grid\n",
    "    if N != int(N):\n",
    "        print(f'delta={delta} does not coincide with mesh')\n",
    "    \n",
    "    # extracting data\n",
    "    else:\n",
    "        print(f'Extracting data on {int(N)}x{int(N)} grid')\n",
    "        idx = create_idx(delta)\n",
    "        pred = np.zeros((num_samples,int(N)**2,14))\n",
    "        for i in range(num_samples):\n",
    "            pred[i,:,:] = full_grid[i,idx[0],idx[1],:]\n",
    "        preds.append(pred)\n",
    "        pred_grids.append(str(int(N)) + 'x' + str(int(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b28b74-8822-42e9-8f7a-6afba4904b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different grid sizes\n",
    "\n",
    "print('Different grid sizes used:')\n",
    "print()\n",
    "for grid in pred_grids:\n",
    "    print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f2db3-4b43-4343-a486-77cc67a335fa",
   "metadata": {},
   "source": [
    "# Compute Normalized Alpha Vectors from Kernel PCA Using LUQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3b3c5-0ae1-49d8-b586-d7e42e884d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning QoI over each grid; same setup as part 3 but with different grid sizes\n",
    "\n",
    "LUQs = []\n",
    "for i, pred in enumerate(preds):\n",
    "    LUQs.append(LUQ(pred[:,:,9]))\n",
    "    LUQs[i].learn_qois_and_transform(num_qoi=2)\n",
    "    \n",
    "# normalize eigenvectors\n",
    "unit_alphas = []\n",
    "for i in range(len(preds)):\n",
    "    unit_alphas.append([])\n",
    "    for j in range(2):\n",
    "        unit_alphas[i].append(LUQs[i].kpcas[0].eigenvectors_[:,j] / np.linalg.norm(LUQs[i].kpcas[0].eigenvectors_[:,j], ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d6d92b-e684-4faf-8491-147f8e525162",
   "metadata": {},
   "source": [
    "# Comparing Alpha Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddeecf-229b-4063-a9c3-6cffd4930af0",
   "metadata": {},
   "source": [
    "## Linear Regression Diagnostics on Alpha Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb73aaf-e948-494f-b4a1-350f5243e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying linear regression for each grid pair\n",
    "from scipy.linalg import lstsq\n",
    "\n",
    "As = []\n",
    "ms = []\n",
    "bs = []\n",
    "R_squared = []\n",
    "for i in range(len(preds)-1):\n",
    "    As.append([])\n",
    "    ms.append([])\n",
    "    bs.append([])\n",
    "    R_squared.append([])\n",
    "    for j in range(2):\n",
    "        As[i].append(np.ones((preds[i].shape[0],2)))\n",
    "        As[i][j][:,1] = unit_alphas[-(i+1)][j]\n",
    "        coeffs, res, _, _ = lstsq(As[i][j], unit_alphas[-(i+2)][j])\n",
    "        ms[i].append(coeffs[1])\n",
    "        bs[i].append(coeffs[0])\n",
    "        SS_tot = np.sum((unit_alphas[-(i+1)][j] - np.mean(unit_alphas[-(i+2)][j]))**2)\n",
    "        R_squared[i].append(1-res/SS_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71614f61-763a-4c63-936a-31f267b3eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing diagnostics\n",
    "spacing = '     '\n",
    "for i in range(len(pred_grids)-1):\n",
    "    print(f'Results between grids {pred_grids[-(i+1)]} and {pred_grids[-(i+2)]}:')\n",
    "    for j in range(2):\n",
    "        print(spacing+f'QoI component {j+1}:')\n",
    "        print(2*spacing+f'slope: {ms[i][j]}')\n",
    "        print(2*spacing+f'R^2: {R_squared[i][j]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495d698-360a-48b4-873d-b20d60351003",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d75361-be06-4968-a92e-e51be9993389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting kpca components per grid\n",
    "\n",
    "m = []\n",
    "M = []\n",
    "Delta = []\n",
    "for i in range(2):\n",
    "    m.append(np.inf)\n",
    "    M.append(-np.inf)\n",
    "    for j in range(len(pred_grids)):\n",
    "        if unit_alphas[-(j+1)][i].min() < m[i]:\n",
    "            m[i] = unit_alphas[-(j+1)][i].min()\n",
    "        if unit_alphas[-(j+1)][i].max() > M[i]:\n",
    "            M[i] = unit_alphas[-(j+1)][i].max()\n",
    "    Delta.append(0.1 * (M[i] - m[i]))\n",
    "\n",
    "param_str = ['a', 'b']\n",
    "for i in range(len(pred_grids)-1):\n",
    "    for j in range(2):\n",
    "        plt.figure()\n",
    "        plt.scatter(unit_alphas[-(i+1)][j], unit_alphas[-(i+2)][j], c=c[0])\n",
    "        plt.xlim([m[j]-Delta[j],M[j]+Delta[j]])\n",
    "        plt.ylim([m[j]-Delta[j],M[j]+Delta[j]])\n",
    "        if j == 0:\n",
    "            component = r'$\\alpha^{(1)}$'\n",
    "        else:\n",
    "            component = r'$\\alpha^{(2)}$'\n",
    "        plt.xlabel(component + f' from {pred_grids[-(i+1)]} grid')\n",
    "        plt.ylabel(component + f' from {pred_grids[-(i+2)]} grid')\n",
    "        x = np.linspace(unit_alphas[-(i+1)][j].min(),\n",
    "                        unit_alphas[-(i+1)][j].max(),\n",
    "                        10000)\n",
    "        y = ms[i][j]*x+bs[i][j]\n",
    "        plt.plot(x, y, c=c[1], label=f'slope = {np.round(ms[i][j],3)}; '+r'$R^2$'+f' = {np.round(R_squared[i][j],3)}')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "#         fn = 'plots/' + pred_grids[-(i+1)] + '_' + pred_grids[-(i+2)] + '_' + str(j+1) + '.png'\n",
    "#         plt.savefig(fn, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
